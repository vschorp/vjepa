app: vjepa
nodes: 1
tasks_per_node: 8 # 8 
data:
  dataset_type: VideoDataset
  datasets:
    - /cluster/home/vschorp/self_supervised_bucket/data/youtube_data_scrape/clips_letsdig/all_clip_paths.csv
  decode_one_clip: true
  batch_size: 8 # 24
  num_clips: 1
  num_frames: 16
  tubelet_size: 2
  sampling_rate: 1 # 4
  crop_size: 224
  patch_size: 16
  pin_mem: true
  num_workers: 12
  filter_short_videos: false
  clip_duration: null
data_aug:
  auto_augment: false
  motion_shift: false
  random_resize_aspect_ratio:
  - 0.75
  - 1.35
  random_resize_scale:
  - 0.3
  - 1.0
  reprob: 0.0
logging:
  folder: /cluster/home/vschorp/self_supervised_bucket/data/checkpoints
  write_tag: jepa
loss:
  loss_exp: 1.0
  reg_coeff: 0.0
mask:
  - aspect_ratio:
      - 0.75
      - 1.5
    num_blocks: 8
    spatial_scale:
      - 0.15
      - 0.15
    temporal_scale:
      - 1.0
      - 1.0
    max_temporal_keep: 1.0
    max_keep: null
  - aspect_ratio:
      - 0.75
      - 1.5
    num_blocks: 2
    spatial_scale:
      - 0.7
      - 0.7
    temporal_scale:
      - 1.0
      - 1.0
    max_temporal_keep: 1.0
    max_keep: null
meta:
  load_checkpoint: true
  read_checkpoint: vitl16.pth.tar
  seed: 234
  eval_freq: 100
  use_sdpa: true
  dtype: float16 # bfloat16
  save_every_freq: 25
model:
  model_name: vit_large
  pred_depth: 12
  pred_embed_dim: 384
  uniform_power: true
  use_mask_tokens: true
  zero_init_mask_tokens: true
optimization:
  ipe: 15000 # 30k for 4 gpus, 15k if 8 gpus, orig 300
  ipe_scale: 1.25
  clip_grad: 10.0
  weight_decay: 0.04
  final_weight_decay: 0.4
  epochs: 600 # 300
  warmup: 40
  start_lr: 0.00002 # 0.0002
  lr: 0.0000625 # 0.000625
  final_lr: 1.0e-06
  ema:
  - 0.998
  - 1.0
