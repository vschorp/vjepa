nodes: 8
tasks_per_node: 8
tag: video-reconstruction-excavator
eval_name: video_reconstruction_frozen
resume_checkpoint: false
data_path: /Users/vincent/self_supervised_bucket/data/
data:
  dataset_type: VideoDataset
  dataset_train: /Users/vincent/self_supervised_bucket/data/datasets/letsdig/train_clips.csv
  dataset_val: /Users/vincent/self_supervised_bucket/data/datasets/letsdig/val_clips.csv
  decode_one_clip: true
  num_clips: 1
  num_frames: 16
  tubelet_size: 2
  sampling_rate: 1 # 4
  crop_size: 224
  patch_size: 16
  pin_mem: true
  num_workers: 12
  filter_short_videos: false
  clip_duration: null
data_aug:
  auto_augment: false
  motion_shift: false
  random_resize_aspect_ratio:
  - 0.75
  - 1.35
  random_resize_scale:
  - 0.3
  - 1.0
  reprob: 0.0
logging:
  folder: logs
optimization:
  num_epochs: 20
  batch_size: 2
  weight_decay: 0.001
  lr: 0.001
  start_lr: 0.001
  final_lr: 0.0
  warmup: 0.
  use_bfloat16: false
pretrain:
  model_name: vit_large
  encoder_checkpoint_key: encoder
  predictor_checkpoint_key: predictor
  clip_duration: null
  uniform_power: true
  use_sdpa: true
  use_silu: false
  tight_silu: false
  pred_depth: 12
  pred_embed_dim: 384
  use_mask_tokens: true
  zero_init_mask_tokens: true
  folder: checkpoints/
  checkpoint: pretrain_orig/vitl16.pth.tar  # name of pretrained model file inside folder
  write_tag: jepa
mask:
  - aspect_ratio:
      - 0.75
      - 1.5
    num_blocks: 8
    spatial_scale:
      - 0.15
      - 0.15
    temporal_scale:
      - 1.0
      - 1.0
    max_temporal_keep: 1.0
    max_keep: null
  - aspect_ratio:
      - 0.75
      - 1.5
    num_blocks: 2
    spatial_scale:
      - 0.7
      - 0.7
    temporal_scale:
      - 1.0
      - 1.0
    max_temporal_keep: 1.0
    max_keep: null